{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kernel density estimation and kernel regression for prediction\n",
    "This notebook is my first attempt to write down the ddiff and dddiff models that I have been working on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mixed recursive/iterative approach (rather than vectorized approach that is harder to generalize\n",
    "- create separate submodules for KDE and KDreg\n",
    "    - develop a system for storing differenced but unweighted data and the appropriate mask to lessen memory usage. \n",
    "        -1's or 0's depending on i/j/k/l/.... values\n",
    "    - figure out the deepest level requested by the user and levels that are less deep are just slices of the deeper model. \n",
    "        -scout out the tree to build the differenced dataset. \n",
    "          \n",
    "        \n",
    " plot and compare\n",
    "on synthetic data, 1, 2, 3+ mixed distributions\n",
    "1d - Ndiff vs gaussian kernel vs kernel_tunneling\n",
    "2d -  \n",
    "\n",
    "\n",
    "multidimensional x problem\n",
    "e.g., parameter treatment\n",
    "\"product kernel approach\" vs l2 \"el two\" (radial basis?)distance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### generate a simple linear dataset y=xb+e\n",
    "##### store validation data from same dataset too"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### create modeldict\n",
    "- 'Ndiff_type': refers to the mathematical form of Ndiff\n",
    "  - 'product'-Ndiff1 multiplied by Ndiff2\n",
    "  - 'recursive'-Ndiff1's bw is Ndiff 2\n",
    "- max_bw_Ndiff: is the depth of Ndiffs applied in estimating the bandwidth.\n",
    "- 'normalize_Ndiffwtsum':\n",
    "  - 'across' means sum across own level of kernelized-Ndiffs and divide by that sum (CDF approach)\n",
    "  - 'own_n' means for (n+k)diff where n+K=max_bw_Ndiff\n",
    "- Ndiff_bw_kern:\n",
    "  - rbfkern means use the radial basis function kernel\n",
    "  - 'product' means use product kernel like as in liu and yang eq1. \n",
    "- 'regression_model':\n",
    "  - 'NW' means use nadaraya-watson kernel regression\n",
    "  - 'NW-rbf' means use NW but calculate p(y,x) using rbf kernel rather than product kernel\n",
    "  - 'full_logit' means local logit with all variables entering linearly\n",
    "  - 'rbf_logit' means local logit with 1 parameters: scaled l2 norm centered on zero \n",
    " (globally or by i?). Is this a new idea?\n",
    "- outer_x_bw_form: if x is separated into blocks of rvars that are combined within a block using rbf kernel, \n",
    "  - 'one_for_all' - use same hx bw for all blocks\n",
    "  - 'one_per_block' - each block or rvars gets an hx\n",
    "- ykern_grid\n",
    "  - if int, then create int evnely spaced values from -3 to 3 (standard normal middle ~99%)\n",
    "  - 'no' means use original data points (self is masked when predicting self)\n",
    "- xkern_grid\n",
    "  - much like ykern_grid, but used less frequently since x's are typically pre-specified\n",
    "- product_kern_norm: when multiplying kernels across random variables, this parameter determines if each random variable has its kernels normalized before the product or not\n",
    "  - 'self' means each random variable has its kernels divided by the sum of kernels across the nout axis (the number of possibile values y is averaged over, whose probabilities sum to 1)\n",
    "  - 'own_n' means same as self, but divided by count of non-masked items in second to last, nout lenght dimension\n",
    "  - 'none' means no normalization prior to taking products across rvar kernels\n",
    "- hyper_param_form_dict is a nested dictionary\n",
    "  - Ndiff_exponent is the exponent wrapped around typically a sum of kernels for each Ndiff level \n",
    "after level 1 (i.e., (i-j) or centered, obvious/conventional level.)\n",
    "  - x_bandscale is the parameter specific to each variable (each x in X) used for prediction (y)\n",
    "  - Ndiff_depth_bw is used as the kernel's bandwidth (h) at each level of Ndiff including at level 1 \n",
    "  - outer_x_bw vanilla bandwidth for the rbf or product kernel\n",
    "  - outer_y_bw vanilla bandwidth for y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "import * only allowed at module level (mykern.py, line 287)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/home/douglas/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3326\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[1;32m\"<ipython-input-1-d93e2c947ff5>\"\u001b[0m, line \u001b[1;32m2\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    import kernelcompare as kc\n",
      "\u001b[0;36m  File \u001b[0;32m\"/home/douglas/gits2/kernelkernel/kernelcompare.py\"\u001b[0;36m, line \u001b[0;32m7\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    import mykern as mk\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"/home/douglas/gits2/kernelkernel/mykern.py\"\u001b[0;36m, line \u001b[0;32m287\u001b[0m\n\u001b[0;31m    def MY_KDEpredict(self,yin,yout,xin,xpr,modeldict,fixed_or_free_paramdict):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m import * only allowed at module level\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import kernelcompare as kc\n",
    "#from importlib import reload\n",
    "networkdir='o:/public/dpatton/kernel'\n",
    "mydir=os.getcwd()\n",
    "#mydir2=os.path.join(mydir,\"old models without datagen\")\n",
    "test=kc.KernelCompare(directory=mydir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=16\n",
    "ykerngrid_form_variations=('modeldict:ykerngrid_form',[('exp',5),('even',4)])\n",
    "lossfn_variations=('modeldict:loss_function',['batch_crossval'])\n",
    "#lossfn_variations=('modeldict:loss_function',['mse'])\n",
    "#Ndiff_type_variations=('modeldict:Ndiff_type',['recursive'])\n",
    "Ndiff_type_variations=('modeldict:Ndiff_type',['product'])\n",
    "max_bw_Ndiff_variations=('modeldict:max_bw_Ndiff',[2])\n",
    "NWnorm_variations=('modeldict:NWnorm',['across'])\n",
    "Ndiff_start_variations=('modeldict:Ndiff_start',[1])\n",
    "ykern_grid_variations=('modeldict:ykern_grid',[n+1])\n",
    "regression_model_variations=('modeldict:regression_model',['NW-rbf'])\n",
    "#product_kern_norm_variations=('modeldict:product_kern_norm',['self','own_n'])#include None too?\n",
    "#normalize_Ndiffwtsum_variations=('modeldict:normalize_Ndiffwtsum',['own_n','across'])\n",
    "optdict_variation_list=[NWnorm_variations,\n",
    "                        ykerngrid_form_variations, \n",
    "                        lossfn_variations,\n",
    "                        regression_model_variations,\n",
    "                        Ndiff_type_variations,\n",
    "                        ykern_grid_variations,\n",
    "                        max_bw_Ndiff_variations,Ndiff_start_variations\n",
    "                       ]  #,product_kern_norm_variations,normalize_Ndiffwtsum_variations]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the default datagen_dict as of 11/25/2019\n",
    "#datagen_dict={'batch_n':32,'batchcount':10, 'param_count':param_count,'seed':1, 'ftype':'linear', 'evar':1, 'source':'monte'}\n",
    "\n",
    "\n",
    "batch_n_variations=('batch_n',[n])\n",
    "batchcount_variations=('batchcount',[7])\n",
    "#ftype_variations=('ftype',['linear','quadratic'])\n",
    "ftype_variations=('ftype',['quadratic'])\n",
    "param_count_variations=('param_count',[4])\n",
    "#need to add block capability to datagen so we can repeat optimization with new training data.\n",
    "\n",
    "datagen_variation_list=[batch_n_variations,batchcount_variations,ftype_variations,param_count_variations]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testrun=test.prep_model_list(optdict_variation_list=optdict_variation_list,datagen_variation_list=datagen_variation_list,verbose=1)\n",
    "'''print(f'len(testrun){len(testrun)}')\n",
    "print(f'testrun[0]{testrun[0:2]}')\n",
    "print('--------------')\n",
    "print(f'testrun[-1]{testrun[-4:]}')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import traceback\n",
    "#from random import shuffle\n",
    "#shuffle(testrun)\n",
    "testrun=testrun[-1::]\n",
    "#a_rundict=testrun[100]#this produced the Ndiff_exponent error for recursive Ndiff\n",
    "for idx in range(1):#len(testrun)):\n",
    "    print(f'~~~~~~~run number:{idx}`~~~~~~~')\n",
    "    a_rundict=testrun[idx]\n",
    "    print(f'a_rundict{a_rundict}')\n",
    "    optimizedict=a_rundict['optimizedict']\n",
    "    datagen_dict=a_rundict['datagen_dict']\n",
    "\n",
    "    try:\n",
    "        test.do_monte_opt(optimizedict,datagen_dict,force_start_params=0)\n",
    "        test.open_condense_resave('model_save',verbose=0)\n",
    "        test.merge_and_condense_saved_models(merge_directory=None,save_directory=None,condense=None,verbose=None)\n",
    "    except:\n",
    "        print('traceback for run',idx)\n",
    "        print(traceback.format_exc())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
