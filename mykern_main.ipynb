{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kernel density estimation and kernel regression for prediction\n",
    "This notebook is my first attempt to write down the ddiff and dddiff models that I have been working on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mixed recursive/iterative approach (rather than vectorized approach that is harder to generalize\n",
    "- create separate submodules for KDE and KDreg\n",
    "    - develop a system for storing differenced but unweighted data and the appropriate mask to lessen memory usage. \n",
    "        -1's or 0's depending on i/j/k/l/.... values\n",
    "    - figure out the deepest level requested by the user and levels that are less deep are just slices of the deeper model. \n",
    "        -scout out the tree to build the differenced dataset. \n",
    "          \n",
    "        \n",
    " plot and compare\n",
    "on synthetic data, 1, 2, 3+ mixed distributions\n",
    "1d - Ndiff vs gaussian kernel vs kernel_tunneling\n",
    "2d -  \n",
    "\n",
    "\n",
    "multidimensional x problem\n",
    "e.g., parameter treatment\n",
    "\"product kernel approach\" vs l2 \"el two\" (radial basis?)distance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### generate a simple linear dataset y=xb+e\n",
    "##### store validation data from same dataset too"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### create modeldict\n",
    "- 'Ndiff_type': refers to the mathematical form of Ndiff\n",
    "  - 'product'-Ndiff1 multiplied by Ndiff2\n",
    "  - 'recursive'-Ndiff1's bw is Ndiff 2\n",
    "- max_bw_Ndiff: is the depth of Ndiffs applied in estimating the bandwidth.\n",
    "- 'normalize_Ndiffwtsum':\n",
    "  - 'across' means sum across own level of kernelized-Ndiffs and divide by that sum (CDF approach)\n",
    "  - 'own_n' means for (n+k)diff where n+K=max_bw_Ndiff\n",
    "- Ndiff_bw_kern:\n",
    "  - rbfkern means use the radial basis function kernel\n",
    "  - 'product' means use product kernel like as in liu and yang eq1. \n",
    "- 'regression_model':\n",
    "  - 'NW' means use nadaraya-watson kernel regression\n",
    "  - 'full_logit' means local logit with all variables entering linearly\n",
    "  - 'rbf_logit' means local logit with 1 parameters: scaled l2 norm centered on zero \n",
    " (globally or by i?). Is this a new idea?\n",
    "- outer_x_bw_form: if x is separated into blocks of rvars that are combined within a block using rbf kernel, \n",
    "  - 'one_for_all' - use same hx bw for all blocks\n",
    "  - 'one_per_block' - each block or rvars gets an hx\n",
    "- ykern_grid\n",
    "  - if int, then create int evnely spaced values from -3 to 3 (standard normal middle ~99%)\n",
    "  - 'no' means use original data points (self is masked when predicting self)\n",
    "- xkern_grid\n",
    "  - much like ykern_grid, but used less frequently since x's are typically pre-specified\n",
    "- product_kern_norm: when multiplying kernels across random variables, this parameter determines if each random variable has its kernels normalized before the product or not\n",
    "  - 'self' means each random variable has its kernels divided by the sum of kernels across the nout axis (the number of possibile values y is averaged over, whose probabilities sum to 1)\n",
    "  - 'own_n' means same as self, but divided by count of non-masked items in second to last, nout lenght dimension\n",
    "  - 'none' means no normalization prior to taking products across rvar kernels\n",
    "- hyper_param_form_dict is a nested dictionary\n",
    "  - Ndiff_exponent is the exponent wrapped around typically a sum of kernels for each Ndiff level \n",
    "after level 1 (i.e., (i-j) or centered, obvious/conventional level.)\n",
    "  - x_bandscale is the parameter specific to each variable (each x in X) used for prediction (y)\n",
    "  - Ndiff_depth_bw is used as the kernel's bandwidth (h) at each level of Ndiff including at level 1 \n",
    "  - outer_x_bw vanilla bandwidth for the rbf or product kernel\n",
    "  - outer_y_bw vanilla bandwidth for y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kernelcompare as kc\n",
    "#from importlib import reload\n",
    "networkdir='o:/public/dpatton/kernel'\n",
    "test=kc.KernelCompare(directory=networkdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(model_save_list:51\n"
     ]
    }
   ],
   "source": [
    "test.print_model_save(filename=\"condensed_model_save\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ndiff_type_variations=('modeldict:Ndiff_type',['recursive','product'])\n",
    "max_bw_Ndiff_variations=('modeldict:max_bw_Ndiff',[2,3])\n",
    "Ndiff_start_variations=('modeldict:Ndiff_start',[1,2])\n",
    "\n",
    "product_kern_norm_variations=('modeldict:product_kern_norm',['self','own_n'])#include None too?\n",
    "normalize_Ndiffwtsum_variations=('modeldict:normalize_Ndiffwtsum',['own_n','across'])\n",
    "optdict_variation_list=[Ndiff_type_variations,max_bw_Ndiff_variations,Ndiff_start_variations,product_kern_norm_variations,normalize_Ndiffwtsum_variations]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a reminder of the options:\n",
    "#datagen_dict={'train_n':60,'n':200, 'param_count':param_count,'seed':1, 'ftype':'linear', 'evar':1}\n",
    "#datagen_variation_list=[test.build_quadratic_datagen_dict_override()] \n",
    "\n",
    "#train_n_variations=('train_n',[30])#so I don't crash my 10 year old laptop at home\n",
    "train_n_variations=('train_n',[30,45,60])\n",
    "ykern_grid_variations=('ykern_grid',[31,46,61])\n",
    "ftype_variations=('ftype',['linear','quadratic'])\n",
    "param_count_variations=('param_count',[1,2])\n",
    "#need to add block capability to datagen so we can repeat optimization with new training data.\n",
    "\n",
    "datagen_variation_list=[train_n_variations,ftype_variations,param_count_variations]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#print(os.getcwd())\n",
    "try:test.open_condense_resave('model_save',verbose=0)\n",
    "except:pass\n",
    "try:test.open_condense_resave('condensed_model_save',verbose=0)\n",
    "except:pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_i:condensed_model_save has 20 saved model(s)\n",
      "0.0%,4.166666666666667%,8.333333333333334%,12.5%,16.666666666666668%,20.833333333333332%,25.0%,29.166666666666668%,33.333333333333336%,37.5%,41.666666666666664%,45.833333333333336%,50.0%,54.166666666666664%,58.333333333333336%,62.5%,66.66666666666667%,70.83333333333333%,75.0%,79.16666666666667%,83.33333333333333%,87.5%,91.66666666666667%,95.83333333333333%,len(final_keep_list):12\n",
      "file_i:model_save has 10 saved model(s)\n",
      "0.0%,14.285714285714286%,28.571428571428573%,42.857142857142854%,57.142857142857146%,71.42857142857143%,85.71428571428571%,len(final_keep_list):1\n",
      "file_i:model_save2 has 11 saved model(s)\n",
      "0.0%,7.6923076923076925%,15.384615384615385%,23.076923076923077%,30.76923076923077%,38.46153846153846%,46.15384615384615%,53.84615384615385%,61.53846153846154%,69.23076923076923%,76.92307692307692%,84.61538461538461%,92.3076923076923%,len(final_keep_list):1\n",
      "0.0%,4.166666666666667%,8.333333333333334%,12.5%,16.666666666666668%,20.833333333333332%,25.0%,29.166666666666668%,33.333333333333336%,37.5%,41.666666666666664%,45.833333333333336%,50.0%,54.166666666666664%,58.333333333333336%,62.5%,66.66666666666667%,70.83333333333333%,75.0%,79.16666666666667%,83.33333333333333%,87.5%,91.66666666666667%,95.83333333333333%,len(final_keep_list):12\n"
     ]
    }
   ],
   "source": [
    "from os import getcwd\n",
    "thisdir=getcwd()\n",
    "test.merge_and_condense_saved_models(merge_directory=thisdir,save_directory=thisdir,condense=1,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_combo_list has 12 variations to run\n",
      "len(datagen_dict_list):12\n",
      "dict_combo_list has 32 variations to run\n",
      "dict_combo_list has 32 variations to run\n",
      "dict_combo_list has 32 variations to run\n",
      "dict_combo_list has 32 variations to run\n",
      "dict_combo_list has 32 variations to run\n",
      "dict_combo_list has 32 variations to run\n",
      "dict_combo_list has 32 variations to run\n",
      "dict_combo_list has 32 variations to run\n",
      "dict_combo_list has 32 variations to run\n",
      "dict_combo_list has 32 variations to run\n",
      "dict_combo_list has 32 variations to run\n",
      "dict_combo_list has 32 variations to run\n",
      "len(testrun)384\n",
      "testrun[0]{'optimizedict': {'opt_settings_dict': {'method': 'Nelder-Mead', 'options': {'xatol': 0.01, 'fatol': 0.1, 'adaptive': True}, 'mse_threshold': 2, 'help_start': 1, 'partial_match': 1}, 'hyper_param_dict': {'Ndiff_exponent': array([0.3, 0.3]), 'x_bandscale': array([1.]), 'outer_x_bw': array([2.7]), 'outer_y_bw': array([2.2]), 'Ndiff_depth_bw': array([0.5, 0.5]), 'y_bandscale': array([1.5])}, 'modeldict': {'Ndiff_type': 'product', 'param_count': 1, 'Ndiff_start': 1, 'max_bw_Ndiff': 2, 'normalize_Ndiffwtsum': 'own_n', 'xkern_grid': 'no', 'ykern_grid': 61, 'outer_kern': 'gaussian', 'Ndiff_bw_kern': 'rbfkern', 'outer_x_bw_form': 'one_for_all', 'regression_model': 'NW', 'product_kern_norm': 'self', 'hyper_param_form_dict': {'Ndiff_exponent': 'free', 'x_bandscale': 'non-neg', 'Ndiff_depth_bw': 'non-neg', 'outer_x_bw': 'non-neg', 'outer_y_bw': 'non-neg', 'y_bandscale': 'non-neg'}}}, 'datagen_dict': {'train_n': 60, 'n': 200, 'param_count': 1, 'seed': 1, 'ftype': 'linear', 'evar': 1}}\n",
      "testrun[-1]{'optimizedict': {'opt_settings_dict': {'method': 'Nelder-Mead', 'options': {'xatol': 0.01, 'fatol': 0.1, 'adaptive': True}, 'mse_threshold': 2, 'help_start': 1, 'partial_match': 1}, 'hyper_param_dict': {'Ndiff_exponent': array([0.3, 0.3]), 'x_bandscale': array([1., 1.]), 'outer_x_bw': array([2.7]), 'outer_y_bw': array([2.2]), 'Ndiff_depth_bw': array([0.5, 0.5]), 'y_bandscale': array([1.5])}, 'modeldict': {'Ndiff_type': 'product', 'param_count': 2, 'Ndiff_start': 2, 'max_bw_Ndiff': 3, 'normalize_Ndiffwtsum': 'across', 'xkern_grid': 'no', 'ykern_grid': 61, 'outer_kern': 'gaussian', 'Ndiff_bw_kern': 'rbfkern', 'outer_x_bw_form': 'one_for_all', 'regression_model': 'NW', 'product_kern_norm': 'own_n', 'hyper_param_form_dict': {'Ndiff_exponent': 'free', 'x_bandscale': 'non-neg', 'Ndiff_depth_bw': 'non-neg', 'outer_x_bw': 'non-neg', 'outer_y_bw': 'non-neg', 'y_bandscale': 'non-neg'}}}, 'datagen_dict': {'train_n': 60, 'n': 200, 'param_count': 2, 'seed': 1, 'ftype': 'quadratic', 'evar': 1}}\n"
     ]
    }
   ],
   "source": [
    "testrun=test.prep_model_list(optdict_variation_list=optdict_variation_list,datagen_variation_list=datagen_variation_list,verbose=1)\n",
    "print(f'len(testrun){len(testrun)}')\n",
    "print(f'testrun[0]{testrun[0]}')\n",
    "print(f'testrun[-1]{testrun[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~run number:0`~~~~~~~\n",
      "a_rundict{'optimizedict': {'opt_settings_dict': {'method': 'Nelder-Mead', 'options': {'xatol': 0.01, 'fatol': 0.1, 'adaptive': True}, 'mse_threshold': 2, 'help_start': 1, 'partial_match': 1}, 'hyper_param_dict': {'Ndiff_exponent': array([0.3, 0.3]), 'x_bandscale': array([1.]), 'outer_x_bw': array([2.7]), 'outer_y_bw': array([2.2]), 'Ndiff_depth_bw': array([0.5, 0.5]), 'y_bandscale': array([1.5])}, 'modeldict': {'Ndiff_type': 'product', 'param_count': 1, 'Ndiff_start': 1, 'max_bw_Ndiff': 2, 'normalize_Ndiffwtsum': 'across', 'xkern_grid': 'no', 'ykern_grid': 61, 'outer_kern': 'gaussian', 'Ndiff_bw_kern': 'rbfkern', 'outer_x_bw_form': 'one_for_all', 'regression_model': 'NW', 'product_kern_norm': 'self', 'hyper_param_form_dict': {'Ndiff_exponent': 'free', 'x_bandscale': 'non-neg', 'Ndiff_depth_bw': 'non-neg', 'outer_x_bw': 'non-neg', 'outer_y_bw': 'non-neg', 'y_bandscale': 'non-neg'}}}, 'datagen_dict': {'train_n': 60, 'n': 200, 'param_count': 1, 'seed': 1, 'ftype': 'quadratic', 'evar': 1}}\n",
      "saved_filename is condensed_model_save, but does not seem to exist\n",
      "--------------no matching models found----------\n",
      "param_valdict:{'Ndiff_exponent': array([0.3, 0.3]), 'x_bandscale': array([1.]), 'outer_x_bw': array([2.7]), 'outer_y_bw': array([2.2]), 'Ndiff_depth_bw': array([0.5, 0.5]), 'y_bandscale': array([1.5])}\n",
      "setup_fixed_or_free_paramdict:{'Ndiff_exponent': {'fixed_or_free': 'free', 'const': 'free', 'location_idx': (0, 2)}, 'x_bandscale': {'fixed_or_free': 'free', 'const': 'non-neg', 'location_idx': (2, 3)}, 'Ndiff_depth_bw': {'fixed_or_free': 'free', 'const': 'non-neg', 'location_idx': (3, 5)}, 'outer_x_bw': {'fixed_or_free': 'free', 'const': 'non-neg', 'location_idx': (5, 6)}, 'outer_y_bw': {'fixed_or_free': 'free', 'const': 'non-neg', 'location_idx': (6, 7)}, 'y_bandscale': {'fixed_or_free': 'free', 'const': 'non-neg', 'location_idx': (7, 8)}, 'free_params': 'outside', 'fixed_params': array([], dtype=float64)}\n",
      "modeldict:{'Ndiff_type': 'product', 'param_count': 1, 'Ndiff_start': 1, 'max_bw_Ndiff': 2, 'normalize_Ndiffwtsum': 'across', 'xkern_grid': 'no', 'ykern_grid': 61, 'outer_kern': 'gaussian', 'Ndiff_bw_kern': 'rbfkern', 'outer_x_bw_form': 'one_for_all', 'regression_model': 'NW', 'product_kern_norm': 'self', 'hyper_param_form_dict': {'Ndiff_exponent': 'free', 'x_bandscale': 'non-neg', 'Ndiff_depth_bw': 'non-neg', 'outer_x_bw': 'non-neg', 'outer_y_bw': 'non-neg', 'y_bandscale': 'non-neg'}}\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "from random import shuffle\n",
    "shuffle(testrun)\n",
    "#a_rundict=testrun[100]#this produced the Ndiff_exponent error for recursive Ndiff\n",
    "for idx in range(len(testrun)):\n",
    "    print(f'~~~~~~~run number:{idx}`~~~~~~~')\n",
    "    a_rundict=testrun[idx]\n",
    "    print(f'a_rundict{a_rundict}')\n",
    "    optimizedict=a_rundict['optimizedict']\n",
    "    datagen_dict=a_rundict['datagen_dict']\n",
    "\n",
    "    try:\n",
    "        test.do_monte_opt(optimizedict,datagen_dict,force_start_params=0)\n",
    "        test.open_condense_resave('model_save',verbose=0)\n",
    "        test.merge_and_condense_saved_models(merge_directory=None,save_directory=None,condense=None,verbose=None)\n",
    "    except:\n",
    "        print('traceback for run',idx)\n",
    "        print(traceback.format_exc())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#-----------------Calibrate/Optimize--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import myreg\n",
    "x=test.train_x\n",
    "y=test.train_y\n",
    "xfull=np.concatenate([np.ones([x.shape[0],1]),x],axis=1)\n",
    "just_linreg=myreg.reg(y,xfull)\n",
    "just_linreg.myreg()\n",
    "print('linreg_mse:',just_linreg.mse)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import show, output_notebook#,curdoc,save, output_file\n",
    "from bokeh.plotting import figure\n",
    "#from bokeh.models import ColumnDataSource, Range1d, BBoxTileSource\n",
    "#from bokeh.layouts import row\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgrid=np.linspace(1,n,n)\n",
    "x=quad_misspec.train_x\n",
    "y=quad_misspec.train_y\n",
    "\n",
    "\n",
    "xgrid=x[:,0]\n",
    "yhat=quad_misspec.optimize_obj.yhat_un_std\n",
    "p=figure(title='y and yhat', plot_width=900, plot_height=500)\n",
    "p.xaxis.axis_label = 'observations'\n",
    "p.scatter(xgrid,y,size=10,color='blue',alpha=0.4,legend='y')\n",
    "#p.line(xgrid,precip,color='blue',alpha=0.6,legend='precipitation')\n",
    "p.scatter(xgrid,yhat,size=5,color='green',alpha=0.9,legend='yhat')\n",
    "p.circle(xgrid,just_linreg.yhat,color='red',legend='just lin reg yhat')\n",
    "p.line(xgrid,np.mean(y))\n",
    "p.legend.location = \"top_left\"\n",
    "#p.yaxis.visible=False\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(yhat)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ypredict=optimized_Ndiff_kernel.predict_tool(xvalidate,optimized_Ndiff_kernel.fixed_or_free_paramdict,modeldict1)\n",
    "prediction_err=yvalidate-ypredict\n",
    "prediction_mse=np.mean(prediction_err**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ma.count_masked(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## class toolcompare(object):"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
